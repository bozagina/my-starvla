
import time
import random
import os
from pathlib import Path
from datetime import datetime

import torch
import torch.nn as nn
from typing import Dict, Any, Tuple, List
import numpy as np
from peft import LoraConfig, get_peft_model
import csv

# Optional logging dependencies
try:
    import swanlab  # type: ignore
    SWANLAB_AVAILABLE = True
    SWANLAB_RUN = None  # type: ignore
except Exception:
    swanlab = None  # type: ignore
    SWANLAB_AVAILABLE = False
    SWANLAB_RUN = None  # type: ignore

try:
    import pandas as pd  # type: ignore
    PANDAS_AVAILABLE = True
except Exception:
    pd = None  # type: ignore
    PANDAS_AVAILABLE = False

# Core OpenVLA components
from experiments.robot.openvla_utils import (
    get_processor,
    get_proprio_projector,
)

# Masks used to extract action-related hidden states
from prismatic.training.train_utils import (
    get_current_action_mask,
    get_next_actions_mask,
)

# Constants
from prismatic.vla.constants import (
    NUM_ACTIONS_CHUNK,
    ACTION_DIM,
    PROPRIO_DIM,
)
from typing import Any

from transformers.models.llama.modeling_llama import LlamaForCausalLM
from rl.utils import get_vla, compute_num_patches, prepare_inputs_batch, forward_vla


class ActorCritic(nn.Module):
    """
    Actor-Critic for OpenVLA-based continuous control.

    forward(inputs_batch) returns:
      - actions_all: sampled actions in (-1, 1), shape (B, NUM_ACTIONS_CHUNK, ACTION_DIM)  [squashed Gaussian]
      - mu_all: mean actions from action_head.predict_action(...), shape (B, NUM_ACTIONS_CHUNK, ACTION_DIM)
      - log_std_all: condition-independent log-std broadcast to all chunks, shape (B, NUM_ACTIONS_CHUNK, ACTION_DIM)
      - value: state value estimate, shape (B,)
    """

    def __init__(self, cfg, torch_dtype: torch.dtype):
        super().__init__()
        self.cfg = cfg

        # Device / dtype
        self.vla = get_vla(cfg, torch_dtype)
        self.device = self.vla.device
        self.model_dtype = torch_dtype
        self.vla = self.vla.to(dtype=self.model_dtype)
        # è®¡ç®—æœ‰æ•ˆçš„vocabèŒƒå›´
        """
        - ä¸€äº›æ¨¡å‹ä¼šå°†è¯è¡¨çŸ©é˜µæŒ‰ pad_to_multiple_of å¯¹é½åˆ°æŸä¸ªå€æ•°ï¼Œå¯¼è‡´å®é™…çŸ©é˜µè¡Œæ•°å¤§äºçœŸå®è¯è¡¨å¤§å°
- è¿™é‡Œé€šè¿‡ vocab_size - pad_to_multiple_of å¾—åˆ°çœŸå®å¯ç”¨çš„è¯è¡¨ä¸Šç•Œï¼Œé¿å…æŠŠå¯¹é½å¡«å……çš„â€œç©ºä½â€è¯¯è®¤ä¸ºæœ‰æ•ˆ token"""
        self.vocab_size = self.vla.config.text_config.vocab_size - self.vla.config.pad_to_multiple_of # ï¼Ÿ
        self.n_action_bins = self.vla.config.n_action_bins
        self.action_vocab_start = self.vocab_size - self.n_action_bins
        
        # åŸåœ°æ›¿æ¢lm_headä¸ºç²¾ç®€ç‰ˆæœ¬
        original_lm_head = self.vla.language_model.lm_head
        # 
        print(f"åŸå§‹ lm_head å½¢çŠ¶: weight={original_lm_head.weight.shape}, "
              f"bias={original_lm_head.bias.shape if original_lm_head.bias is not None else None}") # åŸå§‹ lm_head å½¢çŠ¶: weight=torch.Size([32064, 4096]), bias=None
        
        # æå–æƒé‡å’Œåç½®çš„æœ‰æ•ˆéƒ¨åˆ† [action_vocab_start:vocab_size, :]
        with torch.no_grad():
            action_weight = original_lm_head.weight[self.action_vocab_start:self.vocab_size, :].clone()
            if original_lm_head.bias is not None:
                action_bias = original_lm_head.bias[self.action_vocab_start:self.vocab_size].clone()
            else:
                action_bias = None
        
        # åˆ›å»ºæ–°çš„ç²¾ç®€lm_headå¹¶åŸåœ°æ›¿æ¢
        new_lm_head = nn.Linear(
            original_lm_head.in_features,
            self.n_action_bins,
            bias=(action_bias is not None)
        ).to(self.device).to(dtype=self.model_dtype)
        
        # å¤åˆ¶æƒé‡
        with torch.no_grad():
            new_lm_head.weight.copy_(action_weight)
            if action_bias is not None:
                new_lm_head.bias.copy_(action_bias)
        
        # åŸåœ°æ›¿æ¢
        self.vla.language_model.lm_head = new_lm_head
        """
        - åŸå§‹ lm_head æ˜¯ä¸€ä¸ªçº¿æ€§å±‚ï¼Œæƒé‡å½¢çŠ¶æ˜¯ (vocab_size, hidden_dim) ï¼Œ
        å³ (32064, 4096) ï¼Œè¡¨ç¤ºâ€œæŠŠæ¯ä¸ªä½ç½®çš„éšè—å‘é‡ï¼ˆ4096ç»´ï¼‰æŠ•å½±æˆå¯¹ 32064 ä¸ªè¯çš„ logitsâ€ã€‚
        - ç²¾ç®€åæŠŠè¾“å‡ºé€šé“æ”¹ä¸º n_action_bins ï¼ˆä¾‹å¦‚ 256ï¼‰ï¼Œæƒé‡å½¢çŠ¶å˜ä¸º (256, 4096) ã€‚
        å«ä¹‰æ˜¯â€œæŠŠæ¯ä¸ªä½ç½®çš„éšè—å‘é‡ï¼ˆ4096ç»´ï¼‰æŠ•å½±æˆå¯¹ 256 ä¸ªåŠ¨ä½œ bin çš„ logitsâ€ã€‚
        """
        print(f"ç²¾ç®€å lm_head å½¢çŠ¶: weight={new_lm_head.weight.shape}, "
              f"bias={new_lm_head.bias.shape if new_lm_head.bias is not None else None}")
        print(f"lm_head å·²ä» ({original_lm_head.out_features}, {original_lm_head.in_features}) "
              f"ç²¾ç®€ä¸º ({self.n_action_bins}, {original_lm_head.in_features})")
        
        # ğŸ”’ å†»ç»“ VLA å‚æ•°
        for param in self.vla.parameters():
            param.requires_grad = False
        if cfg.use_lora:
            lora_config = LoraConfig(
                r=cfg.lora_rank,
                lora_alpha=min(cfg.lora_rank, 16),
                lora_dropout=cfg.lora_dropout,
                target_modules="all-linear",
                init_lora_weights="gaussian",
            )
            self.vla = get_peft_model(self.vla, lora_config)
            print("lora_rank:", cfg.lora_rank)
            # æ‰“å°å¯è®­ç»ƒLoraå‚æ•°ä¿¡æ¯
            self.vla.print_trainable_parameters()
        self.vla.language_model: LlamaForCausalLM # ç±»å‹æ³¨é‡Šï¼Œ
        # æ‰‹åŠ¨è§£å†»lm_headå‚æ•°ï¼ˆä¿æŒå…¨å‚é‡è®­ç»ƒï¼‰
        for param in self.vla.language_model.lm_head.parameters():
            param.requires_grad = True
        """
        self.bins
        array([-1.000, -0.992, -0.984, -0.976, -0.969, -0.961, -0.953, -0.945,
            -0.937, -0.929, -0.922, -0.914, -0.906, -0.898, -0.890, -0.882,
            -0.875, -0.867, -0.859, -0.851, -0.843, -0.835, -0.827, -0.820,
            -0.812, -0.804, -0.796, -0.788, -0.780, -0.773, -0.765, -0.757,
            -0.749, -0.741, -0.733, -0.725, -0.718, -0.710, -0.702, -0.694,
            -0.686, -0.678, -0.671, -0.663, -0.655, -0.647, -0.639, -0.631,
            -0.624, -0.616, -0.608, -0.600, -0.592, -0.584, -0.576, -0.569,
            -0.561, -0.553, -0.545, -0.537, -0.529, -0.522, -0.514, -0.506,
            -0.498, -0.490, -0.482, -0.475, -0.467, -0.459, -0.451, -0.443,
            -0.435, -0.427, -0.420, -0.412, -0.404, -0.396, -0.388, -0.380,
            -0.373, -0.365, -0.357, -0.349, -0.341, -0.333, -0.325, -0.318,
            -0.310, -0.302, -0.294, -0.286, -0.278, -0.271, -0.263, -0.255,
            -0.247, -0.239, -0.231, -0.224, -0.216, -0.208, -0.200, -0.192,
            -0.184, -0.176, -0.169, -0.161, -0.153, -0.145, -0.137, -0.129,
            -0.122, -0.114, -0.106, -0.098, -0.090, -0.082, -0.075, -0.067,
            -0.059, -0.051, -0.043, -0.035, -0.027, -0.020, -0.012, -0.004,
            0.004, 0.012, 0.020, 0.027, 0.035, 0.043, 0.051, 0.059, 0.067,
            0.075, 0.082, 0.090, 0.098, 0.106, 0.114, 0.122, 0.129, 0.137,
            0.145, 0.153, 0.161, 0.169, 0.176, 0.184, 0.192, 0.200, 0.208,
            0.216, 0.224, 0.231, 0.239, 0.247, 0.255, 0.263, 0.271, 0.278,
            0.286, 0.294, 0.302, 0.310, 0.318, 0.325, 0.333, 0.341, 0.349,
            0.357, 0.365, 0.373, 0.380, 0.388, 0.396, 0.404, 0.412, 0.420,
            0.427, 0.435, 0.443, 0.451, 0.459, 0.467, 0.475, 0.482, 0.490,
            0.498, 0.506, 0.514, 0.522, 0.529, 0.537, 0.545, 0.553, 0.561,
            0.569, 0.576, 0.584, 0.592, 0.600, 0.608, 0.616, 0.624, 0.631,
            0.639, 0.647, 0.655, 0.663, 0.671, 0.678, 0.686, 0.694, 0.702,
            0.710, 0.718, 0.725, 0.733, 0.741, 0.749, 0.757, 0.765, 0.773,
            0.780, 0.788, 0.796, 0.804, 0.812, 0.820, 0.827, 0.835, 0.843,
            0.851, 0.859, 0.867, 0.875, 0.882, 0.890, 0.898, 0.906, 0.914,
            0.922, 0.929, 0.937, 0.945, 0.953, 0.961, 0.969, 0.976, 0.984,
            0.992, 1.000])
            self.bin_centers
            array([-0.996, -0.988, -0.980, -0.973, -0.965, -0.957, -0.949, -0.941,
            -0.933, -0.925, -0.918, -0.910, -0.902, -0.894, -0.886, -0.878,
            -0.871, -0.863, -0.855, -0.847, -0.839, -0.831, -0.824, -0.816,
            -0.808, -0.800, -0.792, -0.784, -0.776, -0.769, -0.761, -0.753,
            -0.745, -0.737, -0.729, -0.722, -0.714, -0.706, -0.698, -0.690,
            -0.682, -0.675, -0.667, -0.659, -0.651, -0.643, -0.635, -0.627,
            -0.620, -0.612, -0.604, -0.596, -0.588, -0.580, -0.573, -0.565,
            -0.557, -0.549, -0.541, -0.533, -0.525, -0.518, -0.510, -0.502,
            -0.494, -0.486, -0.478, -0.471, -0.463, -0.455, -0.447, -0.439,
            -0.431, -0.424, -0.416, -0.408, -0.400, -0.392, -0.384, -0.376,
            -0.369, -0.361, -0.353, -0.345, -0.337, -0.329, -0.322, -0.314,
            -0.306, -0.298, -0.290, -0.282, -0.275, -0.267, -0.259, -0.251,
            -0.243, -0.235, -0.227, -0.220, -0.212, -0.204, -0.196, -0.188,
            -0.180, -0.173, -0.165, -0.157, -0.149, -0.141, -0.133, -0.125,
            -0.118, -0.110, -0.102, -0.094, -0.086, -0.078, -0.071, -0.063,
            -0.055, -0.047, -0.039, -0.031, -0.024, -0.016, -0.008, 0.000,
            0.008, 0.016, 0.024, 0.031, 0.039, 0.047, 0.055, 0.063, 0.071,
            0.078, 0.086, 0.094, 0.102, 0.110, 0.118, 0.125, 0.133, 0.141,
            0.149, 0.157, 0.165, 0.173, 0.180, 0.188, 0.196, 0.204, 0.212,
            0.220, 0.227, 0.235, 0.243, 0.251, 0.259, 0.267, 0.275, 0.282,
            0.290, 0.298, 0.306, 0.314, 0.322, 0.329, 0.337, 0.345, 0.353,
            0.361, 0.369, 0.376, 0.384, 0.392, 0.400, 0.408, 0.416, 0.424,
            0.431, 0.439, 0.447, 0.455, 0.463, 0.471, 0.478, 0.486, 0.494,
            0.502, 0.510, 0.518, 0.525, 0.533, 0.541, 0.549, 0.557, 0.565,
            0.573, 0.580, 0.588, 0.596, 0.604, 0.612, 0.620, 0.627, 0.635,
            0.643, 0.651, 0.659, 0.667, 0.675, 0.682, 0.690, 0.698, 0.706,
            0.714, 0.722, 0.729, 0.737, 0.745, 0.753, 0.761, 0.769, 0.776,
            0.784, 0.792, 0.800, 0.808, 0.816, 0.824, 0.831, 0.839, 0.847,
            0.855, 0.863, 0.871, 0.878, 0.886, 0.894, 0.902, 0.910, 0.918,
            0.925, 0.933, 0.941, 0.949, 0.957, 0.965, 0.973, 0.980, 0.988,
            0.996])
            special variables:
            [0:255] : [-0.996078431372549, -0.9882352941176471, -0.9803921568627452, -0.9725490196078431, -0.9647058823529412, -0.9568627450980391, -0.9490196078431372, -0.9411764705882353, -0.9333333333333333, -0.9254901960784314, -0.9176470588235295, -0.9098039215686274, -0.9019607843137255, -0.8941176470588235, -0.8862745098039215, -0.8784313725490196, -0.8705882352941177, -0.8627450980392157, -0.8549019607843138, -0.8470588235294118, -0.8392156862745098, -0.8313725490196078, -0.8235294117647058, -0.8156862745098039, -0.807843137254902, -0.8, -0.7921568627450981, -0.7843137254901961, -0.7764705882352941, -0.7686274509803921, -0.7607843137254902, -0.7529411764705882, -0.7450980392156863, -0.7372549019607844, -0.7294117647058824, -0.7215686274509804, -0.7137254901960784, -0.7058823529411764, -0.6980392156862745, -0.6901960784313725, -0.6823529411764706, -0.6745098039215687, -0.6666666666666667, -0.6588235294117647, -0.6509803921568628, -0.6431372549019607, -0.6352941176470588, -0.6274509803921569, -0.6196078431372549, -0.611764705882353, -0.603921568627451, -0.596078431372549, -0.5882352941176471, -0.580392156862745, -0.5725490196078431, -0.5647058823529412, -0.5568627450980392, -0.5490196078431373, -0.5411764705882354, ...]
            dtype: dtype('float64')
            max: 0.996078431372549
            min: -0.996078431372549
            shape: (255,)
            size: 255
        """
    

        self.bins = np.linspace(-1, 1, self.n_action_bins)
        self.bin_centers = (self.bins[:-1] + self.bins[1:]) / 2.0

        # Keep processor for external preparation
        self.processor = get_processor(cfg)
        """
        processor:å›¾æ–‡å¤„ç†å™¨
        proprio_projector: ä¸€ä¸ªå°†æœ¬ä½“æ„Ÿå—çŠ¶æ€ï¼ˆproprioï¼‰æŠ•å½±åˆ°è¯­è¨€æ¨¡å‹åµŒå…¥ç»´åº¦çš„æŠ•å½±æ¨¡å—
        """
        self.proprio_projector = get_proprio_projector(
            cfg, llm_dim=self.vla.llm_dim, proprio_dim=PROPRIO_DIM
        )
        # æ³¨æ„åŠ›æ± åŒ–å±‚
        """
        - ä¸º Critic æä¾›ä¸€ä¸ªå¯å­¦ä¹ çš„â€œæ±‡èšå™¨â€ï¼ŒæŠŠåŠ¨ä½œç›¸å…³çš„éšçŠ¶æ€é›†åˆ (B, N, D) è½¬æˆä¸€ä¸ªå›ºå®šç»´åº¦ (B, D) çš„çŠ¶æ€è¡¨ç¤ºï¼ˆè€Œæ˜¯å¯¹æ‰€æœ‰åŠ¨ä½œç›¸å…³ä½ç½®çš„éšè—å‘é‡åšâ€œåŠ æƒæ±‡èšâ€å½¢æˆä¸€ä¸ªç»¼åˆè¡¨ç¤ºï¼‰ï¼Œ
        å†ç» value_head è¾“å‡ºæ ‡é‡ä»·å€¼ã€‚
        - æœ¬å±‚ä¸ºæ¯ä¸ªåŠ¨ä½œä½ç½®çš„éšè—å‘é‡æ‰“åˆ†ï¼Œsoftmax å¾—åˆ°æƒé‡ï¼Œå†åšåŠ æƒå’Œã€‚è¿™æ · Critic èƒ½æ›´å…³æ³¨å¯¹ä»·å€¼åˆ¤æ–­æ›´é‡è¦çš„åŠ¨ä½œä½ç‚¹ï¼Œè€Œä¸æ˜¯ç®€å•å¹³å‡ã€‚"""
        self.attn_pool = nn.Sequential(
            nn.Linear(self.vla.llm_dim, 1),
        ).to(self.device).to(dtype=self.model_dtype)

        # Value head
        self.value_head = nn.Sequential(
            nn.LayerNorm(self.vla.llm_dim),
            nn.Linear(self.vla.llm_dim, self.vla.llm_dim),
            nn.ReLU(),
            nn.Linear(self.vla.llm_dim, 1),
        )
        # self.safe_load_model("/cpfs01/liuwei_workspace/models/finetune_rl/agent_checkpoint_epoch_6000", strict=True)
        self.to(self.device).to(dtype=self.model_dtype)

    def get_parameter_groups(self) -> List[Dict[str, Any]]:
        """
        å°†å¯è®­ç»ƒå‚æ•°åˆ†ä¸º 'policy' å’Œ 'value' ä¸¤ç»„ã€‚
        è¿™å¯¹äºä¸ºä¸åŒç»„ä»¶è®¾ç½®ä¸åŒçš„å­¦ä¹ ç‡è‡³å…³é‡è¦ã€‚
        """
        self.vla.language_model: LlamaForCausalLM 
        
        # 1. æ”¶é›†æ‰€æœ‰å¯è®­ç»ƒå‚æ•°
        policy_params = list(self.proprio_projector.parameters())
        value_params = []
        
        # 2. æ”¶é›† LoRA é€‚é…å™¨å‚æ•° (policy)
        for name, param in self.vla.named_parameters():
            if param.requires_grad:
                policy_params.append(param)
        
        # 3. æ”¶é›† value head å‚æ•° (value)
        value_params.extend(list(self.value_head.parameters()))
        # æ·»åŠ æ³¨æ„åŠ›æ± åŒ–å±‚å‚æ•°åˆ°ä»·å€¼ç»„
        value_params.extend(list(self.attn_pool.parameters()))

        # 4. éªŒè¯æ²¡æœ‰é—æ¼ä»»ä½•å¯è®­ç»ƒå‚æ•°
        all_trainable_params = set(filter(lambda p: p.requires_grad, self.parameters()))
        grouped_params = set(policy_params) | set(value_params)
        
        # æ‰“å°è°ƒè¯•ä¿¡æ¯
        if all_trainable_params != grouped_params:
            missing_params = all_trainable_params - grouped_params
            print(f"è­¦å‘Š: å‘ç° {len(missing_params)} ä¸ªæœªåˆ†ç»„çš„å¯è®­ç»ƒå‚æ•°:")
            for p in missing_params:
                for n, param in self.named_parameters():
                    if param is p:
                        print(f"  - {n}")
                        break
            raise ValueError("å‚æ•°åˆ†ç»„ä¸å®Œæ•´ï¼è¯·æ£€æŸ¥æœªåˆ†ç»„çš„å‚æ•°ã€‚")
        
        return [
            {"name": "policy", "params": policy_params},
            {"name": "value", "params": value_params},
        ]

    def _extract_actions_hidden(self, last_hidden_states: torch.Tensor, logits: torch.Tensor, labels, has_act_emb) -> torch.Tensor:
        """
        ä» last_hidden_states å’Œ logits ä¸­æå–åŠ¨ä½œç›¸å…³çš„éƒ¨åˆ†ã€‚
        ç”±äºlm_headå·²ç»è¢«ç²¾ç®€ä¸ºåªè¾“å‡ºn_action_binsï¼Œæ‰€ä»¥logitsç›´æ¥å¯ç”¨ã€‚
        
        è¿”å›:
          action_logits: (B, NUM_ACTIONS_CHUNK * ACTION_DIM, n_action_bins)
          actions_hidden_states: (B, NUM_ACTIONS_CHUNK * ACTION_DIM, D)
        """

        """
        - B ï¼šbatch å¤§å°
        - N ï¼šåŠ¨ä½œç›¸å…³ä½ç½®çš„æ€»æ•°ï¼Œç­‰äº NUM_ACTIONS_CHUNK * ACTION_DIMï¼›æ¯ä¸ªä½ç½®å¯¹åº”â€œæŸä¸ªæ—¶é—´æ­¥çš„æŸä¸ªåŠ¨ä½œç»´åº¦â€çš„éšè—å‘é‡
        - D ï¼šè¯­è¨€æ¨¡å‹éšè—ç»´åº¦ self.vla.llm_dim ï¼ˆä¾‹å¦‚ 4096ï¼‰ï¼Œæ˜¯æ¯ä¸ªä½ç½®çš„ç‰¹å¾å‘é‡ç»´åº¦
        """
        ground_truth_token_ids = labels[:, 1:].to(self.device)  # (B, text_len-1)
        # æ ‡è®°â€œå½“å‰åŠ¨ä½œâ€çš„å ä½ token ä½ç½®
        current_action_mask = get_current_action_mask(ground_truth_token_ids)  # (B, text_len-1)
        # æ ‡è®°â€œä¸‹ä¸€æ­¥åŠ¨ä½œâ€çš„å ä½ token ä½ç½®
        next_actions_mask = get_next_actions_mask(ground_truth_token_ids)      # (B, text_len-1)
        # å¹¶é›†ï¼Œè¡¨ç¤ºâ€œå½“å‰+ä¸‹ä¸€æ­¥â€æ‰€æœ‰åŠ¨ä½œä½ç‚¹
        action_mask = current_action_mask | next_actions_mask


        # æ˜¯åºåˆ—æœ€å‰é¢â€œéæ–‡æœ¬â€éƒ¨åˆ†çš„é•¿åº¦ï¼Œç”¨æ¥å®šä½æ–‡æœ¬æ®µçš„èµ·å§‹ä½ç½®ã€‚
        num_patches = self._compute_num_patches()
        if has_act_emb:
            num_patches += 1
        text_hidden_states = last_hidden_states[:, num_patches:-1]  # (B, text_len, D)
        text_logits = logits[:, num_patches:-1]  # (B, text_len, n_action_bins) - å·²ç»æ˜¯ç²¾ç®€åçš„

        B, _, D = text_hidden_states.shape
        actions_hidden_states = (
            text_hidden_states[action_mask]
            .reshape(B, NUM_ACTIONS_CHUNK * ACTION_DIM, D)
            .to(self.model_dtype)
        )
        
        # æå–åŠ¨ä½œå¯¹åº”çš„logitsï¼ˆå·²ç»æ˜¯ç²¾ç®€åçš„256ç»´ï¼‰
        action_logits = text_logits[action_mask].reshape(B, NUM_ACTIONS_CHUNK * ACTION_DIM, self.n_action_bins)
        
        return action_logits, actions_hidden_states

    def _forward_vla(self, batch: Dict[str, torch.Tensor]):
        return forward_vla(self, batch)

    def _compute_value_from_hidden(self, actions_hidden_states: torch.Tensor) -> torch.Tensor:
        """
        ä½¿ç”¨æ³¨æ„åŠ›æ± åŒ–è®¡ç®—çŠ¶æ€ä»·å€¼
        actions_hidden_states: (B, num_tokens, D)
        """

        
        # 1. è®¡ç®—æ³¨æ„åŠ›åˆ†æ•°
        """
        attn_poolå¯ä»¥ç†è§£æˆé€ä½ç½®æ‰“åˆ†å™¨ï¼Œä¸ºæ¯ä¸ªåŠ¨ä½œä½ç‚¹ï¼ˆæ—¶é—´æ­¥ Ã— åŠ¨ä½œç»´åº¦ï¼‰è®¡ç®—ä¸€ä¸ªå¯å­¦ä¹ çš„â€œé‡è¦æ€§åˆ†æ•°â€
        """
        scores = self.attn_pool(actions_hidden_states)  # (B, num_tokens, 1)
        
        
        # 2. åº”ç”¨softmaxè·å–æ³¨æ„åŠ›æƒé‡
        """
        æ²¿åºåˆ—ç»´ dim=1 å½’ä¸€åŒ–ï¼Œä½¿æ¯ä¸ªæ ·æœ¬çš„æƒé‡æ€»å’Œä¸º 1ï¼Œå½¢æˆå¯¹æ‰€æœ‰åŠ¨ä½œä½ç‚¹çš„æ¦‚ç‡åˆ†å¸ƒ
        """
        weights = torch.softmax(scores, dim=1)  # (B, num_tokens, 1)
        
        # 3. åŠ æƒå¹³å‡å¾—åˆ°æ± åŒ–è¡¨ç¤º
        pooled = torch.sum(weights * actions_hidden_states, dim=1)  # (B, D)
        
        # 4. é€šè¿‡ä»·å€¼å¤´è®¡ç®—æœ€ç»ˆä»·å€¼
        value = self.value_head(pooled).squeeze(-1)  # (B,)
        return value.to(torch.float32)

    def forward(self, inputs_batch: Dict[str, Any], return_vit_out=False) -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor, torch.Tensor]:
        """
        Returns:
          action_logits: (B, NUM_ACTIONS_CHUNK * ACTION_DIM, n_action_bins)
          value:         (B,)
        """
        # Sanity checks
        for k in ("input_ids", "attention_mask", "pixel_values", "labels", "proprio"):
            if k not in inputs_batch:
                raise KeyError(f"inputs_batch missing key: {k}")

        # 1. VLAå‰å‘ä¼ æ’­è·å–éšè—çŠ¶æ€å’Œlogits
        output = self._forward_vla(inputs_batch)
        last_hidden_states = output.hidden_states[-1]  # (B, seq_len, D)
        """
        æœ€åä¸€å±‚: last_hidden_states = output.hidden_states[-1] å–çš„æ˜¯è¯­è¨€æ¨¡å‹æœ€åä¸€ä¸ª Transformer Block çš„è¾“å‡ºï¼Œå³â€œæœ€ç»ˆçš„ä¸Šä¸‹æ–‡è¡¨å¾â€
        """
        logits = output.logits  # (B, seq_len, n_action_bins) - å·²ç»æ˜¯ç²¾ç®€åçš„

        """
        æ•°æ®æµ: å…ˆå¾—åˆ° last_hidden_states (B, seq_len, D) ï¼Œå†ç”¨ç²¾ç®€åçš„ lm_head: R^D -> R^256 æŠ•å½±ä¸ºåˆ†ç±» logits (B, seq_len, 256) , logitsæ˜¯æœªç»è¿‡softmaxçš„åˆ†æ•°
        """

        logits = output.logits
        action_logits, actions_hidden_states = self._extract_actions_hidden(last_hidden_states, logits, inputs_batch['labels'], has_act_emb=("this_act_emb" in inputs_batch))

        # 3. è®¡ç®—ä»·å€¼å‡½æ•°
        value = self._compute_value_from_hidden(actions_hidden_states.detach())  # (B,)

        if return_vit_out:
            return action_logits, value.to(torch.float32), output.projector_features.to(torch.float32)
        else:
            return action_logits, value.to(torch.float32)

    def post_process(self, logits: torch.Tensor, deterministic: List[bool]) -> Tuple[torch.distributions.Categorical, torch.Tensor, np.ndarray]:
        """
        åå¤„ç†logitsä»¥ç”ŸæˆåŠ¨ä½œã€‚
        æ³¨æ„ï¼šç°åœ¨logitså·²ç»æ˜¯ç²¾ç®€åçš„ (B, num_dims, n_action_bins)ï¼Œæ— éœ€å†æˆªå–ã€‚
        """
        # åˆ›å»ºåˆ†å¸ƒå¹¶è®¡ç®—ä¸¤ç§åŠ¨ä½œ
        dist = torch.distributions.Categorical(logits=logits)
        stochastic_tokens = dist.sample()
        deterministic_tokens = torch.argmax(logits, dim=-1)
        """
        - stochastic_tokens æ˜¯æŒ‰ Categorical(logits=logits) åœ¨æ¯ä¸ªåŠ¨ä½œä½ç‚¹éšæœºé‡‡æ ·å¾—åˆ°çš„ token idï¼Œå½¢çŠ¶ (B, N) ï¼Œå¯¹åº”æ¯ä¸ªæ ·æœ¬ã€æ¯ä¸ªåŠ¨ä½œä½ç‚¹çš„éšæœºé€‰æ‹©ã€‚
    - deterministic_tokens æ˜¯å¯¹æ¯ä¸ªåŠ¨ä½œä½ç‚¹çš„ logits åš argmax å¾—åˆ°çš„æœ€å¤§æ¦‚ç‡çš„ token idï¼Œå½¢çŠ¶ (B, N) ï¼Œå¯¹åº”è´ªå¿ƒé€‰æ‹©ã€‚
        """
        is_deterministic_tensor = torch.tensor(
            deterministic, dtype=torch.bool, device=logits.device
        )
        is_deterministic_tensor = is_deterministic_tensor.unsqueeze(1)
        action_token_ids = torch.where(
            is_deterministic_tensor, deterministic_tokens, stochastic_tokens
        )
        """
        action_token_ids: torch.Size([10, 56])
        56 çš„æ¥æºï¼š N = NUM_ACTIONS_CHUNK * ACTION_DIM
        - æ¯ä¸ªæ ·æœ¬çš„ 56 ä¸ªä½ç½®è¡¨ç¤ºï¼š
        - 8 ä¸ªæ—¶é—´æ­¥ï¼ˆopen-loop çš„åŠ¨ä½œåºåˆ—é•¿åº¦ï¼Œ NUM_ACTIONS_CHUNK=8 ï¼‰
        - æ¯ä¸ªæ—¶é—´æ­¥çš„ 7 ä¸ªåŠ¨ä½œç»´åº¦ï¼ˆ ACTION_DIM=7 ï¼‰
        - æ‰€ä»¥è¿™ 56 ä¸ªä½ç½®å°±æ˜¯â€œæŒ‰æ—¶é—´æ­¥Ã—ç»´åº¦å±•å¼€â€çš„æ‰€æœ‰åŠ¨ä½œä½ç‚¹
        - å€¼åŸŸï¼š action_token_ids[b, t] âˆˆ [0, n_action_bins-1] æ˜¯ç¬¬ b ä¸ªæ ·æœ¬åœ¨ç¬¬ t ä¸ªåŠ¨ä½œä½ç‚¹é€‰æ‹©çš„ç¦»æ•£ bin ç´¢å¼•ï¼ˆæ¥è‡ªè´ªå¿ƒæˆ–é‡‡æ ·ï¼‰ï¼Œéšåä¼šæ˜ å°„ä¸ºå½’ä¸€åŒ–è¿ç»­å€¼ã€‚
        
        """

        # å°†token IDè½¬æ¢ä¸ºbinç´¢å¼•ï¼ˆæ³¨æ„ï¼šç°åœ¨action_token_idsèŒƒå›´æ˜¯0åˆ°n_action_bins-1ï¼‰
        # åå‘ç´¢å¼•åˆ°åˆ†ç®±ä¸­å¿ƒ
        actions_from_tokens = self.n_action_bins - 1 - action_token_ids
        # è¾¹ç•Œè£å‰ªåˆ°ä¸­å¿ƒç´¢å¼•èŒƒå›´
        discretized = np.clip(actions_from_tokens.cpu().numpy(), a_min=0, a_max=self.bin_centers.shape[0] - 1)
        # æŸ¥è¡¨å¾—åˆ°è¿ç»­å€¼å¹¶æ•´å½¢
        normalized_actions = self.bin_centers[discretized]  # å½¢çŠ¶ (B, NUM_ACTIONS_CHUNK * ACTION_DIM)
        normalized_actions = normalized_actions.reshape(
            normalized_actions.shape[0], NUM_ACTIONS_CHUNK, ACTION_DIM
        ) # (10, 8, 7)
        
        return dist, action_token_ids, normalized_actions

    def prepare_inputs_batch(self, inp, max_len=None):
        return prepare_inputs_batch(self, inp, max_len)

    def get_norm_stats(self):
        return self.vla.norm_stats[self.cfg.unnorm_key]["proprio"]

    def _compute_num_patches(self):
        return compute_num_patches(self.vla, self.cfg)

    def save_model(self, save_path, epoch: int | None = None):
        """
        ä¿å­˜æ¨¡å‹çš„ LoRA æƒé‡å’Œé¢å¤–å±‚
        """
        from transformers import AutoConfig, AutoImageProcessor, AutoModelForVision2Seq, AutoProcessor
        from peft import PeftModel
        import torch.distributed as dist
        import copy

        save_path = Path(save_path)
        # save_path.mkdir(parents=True, exist_ok=True)
        suffix = f"_epoch_{epoch}" if epoch is not None else ""

        save_path = save_path/ f"agent_checkpoint{suffix}"
        save_path.mkdir(parents=True, exist_ok=True)

        agent_lora_path = save_path / f"agent_lora"
        self.vla.save_pretrained(agent_lora_path)
        print(f"âœ“ Agent LoRA æƒé‡å·²ä¿å­˜åˆ°: {agent_lora_path}")
        
        agent_extra_layers = {
            "value_head": self.value_head.state_dict(),
            "attn_pool": self.attn_pool.state_dict(),
            "lm_head": self.vla.language_model.lm_head.state_dict(),
        }
        # é¢å¤–è¡¥é½ï¼šä¿å­˜ proprio_projectorï¼ˆå› ä¸ºå®ƒåœ¨ policy é‡Œä¼šè®­ç»ƒï¼‰
        if hasattr(self, "proprio_projector") and self.proprio_projector is not None:
            agent_extra_layers["proprio_projector"] = self.proprio_projector.state_dict()

        agent_extra_path = save_path / f"agent_extra_layers.pt"
        torch.save(agent_extra_layers, agent_extra_path)
        print(f"âœ“ Agent é¢å¤–å±‚å·²ä¿å­˜åˆ°: {agent_extra_path}")

    def safe_load_model(self, checkpoint_dir: str | Path, strict: bool = True):
        """
        åŠ è½½æ¨¡å‹çš„ LoRA æƒé‡å’Œé¢å¤–å±‚
        è¯¥æ–¹æ³•ä¸ä¼šä¿®æ”¹ä¼ å…¥çš„vlaæ¨¡å‹ç»“æ„ï¼Œä»…åŠ è½½æƒé‡
        """
        from peft import PeftModel
        from rl.utils import load_lora_inplace

        checkpoint_dir = Path(checkpoint_dir)

        # 1) æŒ‚è½½ LoRA é€‚é…å™¨ -ä¸å¯ä½¿ç”¨PeftModel.from_pretrainedï¼Œä¼šå°†åŸæœ¬çš„peftmodelç»“æ„çš„vlaå†æ¬¡åµŒå¥—ä¸€å±‚peftç»“æ„ 
        lora_dir = checkpoint_dir / "agent_lora"
        if lora_dir.exists(): 
            assert isinstance(self.vla, PeftModel) 
            load_lora_inplace(self.vla, lora_dir) 
            print(f"âœ“ Agent LoRA æƒé‡å·²å®‰å…¨åŠ è½½") 
        else: 
            print(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ° Agent LoRA æƒé‡: {lora_dir}")

        # 2) åŠ è½½é¢å¤–å±‚
        extra_path = checkpoint_dir / "agent_extra_layers.pt"
        sd = torch.load(extra_path, map_location=self.device)

        self.vla.language_model.lm_head.to(self.device).to(self.model_dtype)
        self.value_head.to(self.device).to(self.model_dtype)
        self.attn_pool.to(self.device).to(self.model_dtype)
        if hasattr(self, "proprio_projector") and self.proprio_projector is not None:
            self.proprio_projector.to(self.device).to(self.model_dtype)

        self.vla.language_model.lm_head.load_state_dict(sd["lm_head"], strict=strict)
        self.value_head.load_state_dict(sd["value_head"], strict=strict)
        self.attn_pool.load_state_dict(sd["attn_pool"], strict=strict)
        if "proprio_projector" in sd and self.proprio_projector is not None:
            self.proprio_projector.load_state_dict(sd["proprio_projector"], strict=strict)

        print(f"âœ… å·²ä» {checkpoint_dir} åŠ è½½ LoRA ä¸é¢å¤–å±‚")
    
    def load_lora_and_merge_for_eval(self, checkpoint_dir: str | Path, keep_dtype: torch.dtype, strict: bool = True):
        """
        <è¯„ä¼°å‰> åˆå¹¶æ€»ä½“æ¨¡å‹ï¼Œå¹¶è¾“å‡ºä¸¤ä»½äº§ç‰©ï¼š
        1) agent_merged_for_eval/   â€”â€” åˆå¹¶åçš„éª¨å¹²ï¼ˆå‰”é™¤ lm_headï¼‰
        2) agent_extra_layers.pt    â€”â€” å¤–æŒ‚å¤´ + ç²¾ç®€ lm_headï¼ˆå·²åˆå¹¶åçš„æ™®é€š Linearï¼‰+ norm_stats
        """
        from peft import PeftModel
        from rl.utils import load_lora_inplace
        import torch, copy

        checkpoint_dir = Path(checkpoint_dir)

        # 1) æŒ‚è½½ LoRA
        lora_dir = checkpoint_dir / "agent_lora"
        assert isinstance(self.vla, PeftModel), "self.vla éœ€è¦æ˜¯ PeftModel æ‰èƒ½ merge_and_unload"
        load_lora_inplace(self.vla, lora_dir)
        print(f"âœ“ Agent LoRA æƒé‡å·²åŠ è½½")

        # å…ˆæŠŠ norm_stats å–å‡ºæ¥ï¼Œé¿å… merge æ—¶ä¸¢å¤±è‡ªå®šä¹‰å±æ€§
        cached_norm_stats = copy.deepcopy(getattr(self.vla, "norm_stats", None))

        # 2) åˆå¹¶ LoRA
        self.vla = self.vla.merge_and_unload()

        # 3) dtype/è®¾å¤‡ & è§£ç»‘ tie
        self.vla = self.vla.to(device=self.device, dtype=keep_dtype)
        if hasattr(self.vla.config, "tie_word_embeddings"):
            self.vla.config.tie_word_embeddings = False
        if hasattr(self.vla, "tie_weights"):
            self.vla.tie_weights = lambda *a, **k: None

        # æŠŠä¸¢å¤±çš„ norm_stats æ”¾å›å»ï¼ˆå¦‚æœåŸæ¥æœ‰ï¼‰
        if cached_norm_stats is not None:
            setattr(self.vla, "norm_stats", cached_norm_stats)
            print(f"âœ“ norm_stats: {cached_norm_stats} æ”¾å›")

        print(f"âœ“ Agent LoRA æƒé‡å·²åˆå¹¶åˆ°åŸºåº§æ¨¡å‹")

        # 4) ä¿å­˜ï¼šéª¨å¹²ï¼ˆå‰”é™¤ lm_headï¼‰
        save_path = checkpoint_dir / "agent_merged_for_eval"
        save_path.mkdir(parents=True, exist_ok=True)

        full_sd = self.vla.state_dict()
        filtered_sd = {k: v for k, v in full_sd.items()
                    if not k.endswith("lm_head.weight") and not k.endswith("lm_head.bias")}
        self.vla.save_pretrained(save_path, state_dict=filtered_sd)
        print(f"âœ“ å·²ä¿å­˜åˆå¹¶åçš„éª¨å¹²åˆ°: {save_path}(å·²å‰”é™¤ lm_head)")

        # 5) ä¿å­˜ extraï¼šç²¾ç®€ lm_headï¼ˆå·²åˆå¹¶ï¼Œæ™®é€š Linearï¼‰+ å¤–æŒ‚å¤´ + norm_stats
        extra_out = {}
        with torch.no_grad():
            extra_out["lm_head"] = {k: v.detach().cpu() for k, v in self.vla.language_model.lm_head.state_dict().items()}
            extra_out["value_head"] = {k: v.detach().cpu() for k, v in self.value_head.state_dict().items()}
            extra_out["attn_pool"]  = {k: v.detach().cpu() for k, v in self.attn_pool.state_dict().items()}
            if hasattr(self, "proprio_projector") and self.proprio_projector is not None:
                extra_out["proprio_projector"] = {k: v.detach().cpu() for k, v in self.proprio_projector.state_dict().items()}
            # ç›´æ¥æŠŠ Python dict å­˜èµ·æ¥ï¼ˆtorch.save æ”¯æŒä»»æ„ Python å¯¹è±¡ï¼‰
            extra_out["norm_stats"] = copy.deepcopy(getattr(self.vla, "norm_stats", None))

        extra_path = checkpoint_dir / "agent_extra_layers.pt"
        torch.save(extra_out, extra_path)
        print(f"âœ“ å·²é‡å†™ extra å±‚åˆ°: {extra_path}ï¼ˆå«ç²¾ç®€ lm_head ä¸ norm_stats)")

    def load_merged_model_for_eval(
        self,
        path: str | Path,
        keep_dtype: torch.dtype,
        strict: bool = True,
        device: torch.device | str | None = None,
    ):
        from transformers import AutoModelForVision2Seq
        import os, copy, torch
        path = Path(path)
        device = device or self.device

        os.environ.setdefault("HF_HUB_OFFLINE", "1")
        os.environ.setdefault("TRANSFORMERS_OFFLINE", "1")

        # 1) å®šä½ç›®å½•
        if (path / "agent_merged_for_eval" / "config.json").exists():
            merged_dir = path / "agent_merged_for_eval"
            extra_path = path / "agent_extra_layers.pt"
        elif (path / "config.json").exists():
            merged_dir = path
            extra_path = path.parent / "agent_extra_layers.pt"
        else:
            raise FileNotFoundError(f"æœªæ‰¾åˆ°åˆå¹¶æ¨¡å‹çš„ config.json: {path}")

        print(f"[load] è¯»å–åˆå¹¶ä¸»å¹²: {merged_dir}", flush=True)

        # 2) CPU ä¸ŠåŠ è½½éª¨å¹²ï¼ˆæ—  lm_headï¼‰
        self.vla = AutoModelForVision2Seq.from_pretrained(
            str(merged_dir),
            torch_dtype=None,            # å…ˆä¸è®¾ dtype
            low_cpu_mem_usage=True,
            trust_remote_code=True,
            local_files_only=True,
            device_map="cpu",
        )
        self.vla.vision_backbone.set_num_images_in_input(2)
        print("[load] ä¸»å¹²åŠ è½½å®Œæˆ", flush=True)

        # 3) è§£ç»‘ tie
        if hasattr(self.vla.config, "tie_word_embeddings"):
            self.vla.config.tie_word_embeddings = False
        if hasattr(self.vla, "tie_weights"):
            self.vla.tie_weights = lambda *a, **k: None

        # 4) å®‰è£…ç²¾ç®€å¤´ + æ¢å¤å¤–æŒ‚å¤´ + æ¢å¤ norm_statsï¼ˆéƒ½å…ˆåœ¨ CPUï¼‰
        if extra_path.exists():
            print(f"[load] è¯»å– extra å±‚: {extra_path}", flush=True)
            sd = torch.load(extra_path, map_location="cpu")

            # lm_head
            old_head = self.vla.language_model.lm_head
            in_features = old_head.in_features
            slim_head = nn.Linear(in_features, self.n_action_bins, bias=(old_head.bias is not None))
            slim_head.load_state_dict(sd["lm_head"], strict=True)
            self.vla.language_model.lm_head = slim_head

            # å¤–æŒ‚å¤´
            self.value_head.load_state_dict(sd["value_head"], strict=strict)
            self.attn_pool.load_state_dict(sd["attn_pool"], strict=strict)
            if "proprio_projector" in sd and getattr(self, "proprio_projector", None) is not None:
                self.proprio_projector.load_state_dict(sd["proprio_projector"], strict=strict)

            # norm_stats
            loaded_norm_stats = sd.get("norm_stats", None)
            if loaded_norm_stats is not None:
                setattr(self.vla, "norm_stats", loaded_norm_stats)
            print("[load] extra å±‚åŠ è½½å®Œæˆ", flush=True)
        else:
            # æ²¡æœ‰ extra ä¹Ÿè¦ä¿è¯å¤´å°ºå¯¸æ­£ç¡®ï¼ˆè£…ç©ºçš„ç²¾ç®€å¤´ï¼‰
            old_head = self.vla.language_model.lm_head
            in_features = old_head.in_features
            self.vla.language_model.lm_head = nn.Linear(in_features, self.n_action_bins, bias=(old_head.bias is not None))
            print(f"[load] æœªæ‰¾åˆ° extra å±‚æ–‡ä»¶ï¼ˆå·²å®‰è£…ç©ºçš„ç²¾ç®€ lm_headï¼‰: {extra_path}", flush=True)

        # ç¡®ä¿èƒ½è¿”å› hidden_states
        if hasattr(self.vla.config, "output_hidden_states"):
            self.vla.config.output_hidden_states = True

        # 5) ç»Ÿä¸€æ¬åˆ°ç›®æ ‡ device/dtype
        print(f"[load] æ¬è¿åˆ°è®¾å¤‡: {device}, dtype={keep_dtype}", flush=True)
        self.vla = self.vla.to(device=device, dtype=keep_dtype)
        self.value_head = self.value_head.to(device, dtype=keep_dtype)
        self.attn_pool  = self.attn_pool.to(device, dtype=keep_dtype)
        if hasattr(self, "proprio_projector") and self.proprio_projector is not None:
            self.proprio_projector = self.proprio_projector.to(device, dtype=keep_dtype)

        # 6) å…œåº•ï¼šå¦‚æœ cfg.unnorm_key ä¸åœ¨ norm_statsï¼Œå°½é‡åšä¸€æ¬¡åˆç† fallbackï¼ˆå¹¶æç¤ºï¼‰
        ns = getattr(self.vla, "norm_stats", None)
        if ns is None or not isinstance(ns, dict):
            print("âš ï¸ æ³¨æ„ï¼šæ¨¡å‹å†…æœªå‘ç° norm_statsï¼Œå°†åˆ›å»ºç©ºå­—å…¸ï¼›å¯èƒ½å½±å“åŠ¨ä½œåå½’ä¸€åŒ–ã€‚")
            setattr(self.vla, "norm_stats", {})
            ns = self.vla.norm_stats

        target_key = getattr(self.cfg, "unnorm_key", None)
        if target_key and target_key not in ns:
            # å°è¯• fallbackï¼šä¼˜å…ˆ default / fallback ä¹‹ç±»ï¼›å¦åˆ™å–ç¬¬ä¸€ä¸ª key
            cand = None
            for k in ("default", "libero_default", "fallback"):
                if k in ns:
                    cand = k
                    break
            if cand is None and len(ns) > 0:
                cand = next(iter(ns.keys()))
            if cand is not None:
                print(f"âš ï¸ unnorm_key='{target_key}' ä¸åœ¨ norm_stats ä¸­ï¼Œä¸´æ—¶å›é€€ä¸º '{cand}'ã€‚å¯åœ¨ cfg ä¸­æ”¹æˆæ­¤ keyã€‚")
                # ä¸ç›´æ¥æ”¹ cfgï¼Œä¿æŒä»…è¿è¡Œæ—¶æ›¿ä»£ï¼ˆä½ çš„ check_unnorm_key ä¼šè¯» model.norm_statsï¼‰
                # å¦‚æœä½ å¼ºä¾èµ– cfg.unnorm_keyï¼Œä¸” check æ˜¯ assertï¼Œå¯ä»¥è€ƒè™‘ï¼šself.cfg.unnorm_key = cand
            else:
                # æ²¡æœ‰ä»»ä½•å¯ç”¨é¡¹ï¼Œç»™å‡ºè¯¦ç»†æç¤º
                ks = list(ns.keys())
                raise AssertionError(
                    f"Action un-norm key '{target_key}' ä¸åœ¨ VLA.norm_stats ä¸­ï¼Œä¸”æ‰¾ä¸åˆ°ä»»ä½•å¯ç”¨é¡¹ã€‚"
                    f" è¯·ç¡®è®¤è®­ç»ƒæ—¶ä¿å­˜çš„ norm_stats å·²éš extra å†™å…¥ã€‚å½“å‰å¯ç”¨ keys: {ks}"
                )

        self.vla.eval()
        print("âœ… åˆå¹¶æ¨¡å‹ä¸ extra å±‚åŠ è½½å®Œæˆï¼Œå¯ç”¨äºè¯„ä¼°/æ¨ç†ã€‚", flush=True)

if __name__ == "__main__":
    import sys
    import numpy as np

    # Libero env wrapper and helpers
    from rl.libero_env import LiberoEnvWrapper
    from rl.utils import prepare_one_obs, check_unnorm_key
    from experiments.robot.libero.libero_utils import GenerateConfig, TaskSuite

    # Precision policy to match the example
    USE_BF16: bool = True
    TORCH_DTYPE = torch.bfloat16 if USE_BF16 else torch.float32

    # åœ¨è¿™é‡Œè®¾ç½®è¦å¹¶è¡Œå¤„ç†çš„ç¯å¢ƒæ•°é‡
    ENVS_ID = list(range(10))
    envs_num = len(ENVS_ID)
    BENCHMARK = TaskSuite.LIBERO_SPATIAL
    unnorm_key = f"{BENCHMARK}_no_noops"
    checkpoint_base_dir = ""
    goal_checkpoint="/cpfs01/liuwei_workspace/models/finetune_im/goal_no_noops_resume+libero_goal_no_noops+b32+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--8_acts_chunk--discrete_acts--proprio_state"
    object_checkpoint="/cpfs01/liuwei_workspace/models/finetune_im/openvla-7b+libero_object_no_noops+b40+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--8_acts_chunk--discrete_acts--proprio_state--100000_chkpt"
    four_suites_checkpoint = "/cpfs01/liuwei_workspace/models/finetune_im/openvla-7b+libero_4_task_suites_no_noops+b32+lr-0.0005+lora-r32+dropout-0.0--image_aug--parallel_dec--8_acts_chunk--discrete_acts--proprio_state--4tasks--70000_chkpt"
    
    # Instantiate config
    cfg = GenerateConfig(
        pretrained_checkpoint=four_suites_checkpoint,
        use_l1_regression=False,
        use_diffusion=False,
        use_film=False,
        num_images_in_input=2,
        use_proprio=True,
        load_in_8bit=False,
        load_in_4bit=False,
        center_crop=True,
        num_open_loop_steps=NUM_ACTIONS_CHUNK,
        unnorm_key=unnorm_key,
        device="cuda:4",
    )

    # åˆ›å»ºç­–ç•¥
    actor = ActorCritic(cfg, TORCH_DTYPE)

    # # #==ä¿å­˜ä¸åŠ è½½æ¨¡å‹==
    # print("\n æ¨¡å‹åˆå§‹åŒ–å®Œæˆã€‚å¼€å§‹æµ‹è¯• save_model ...")
    # # === è°ƒç”¨ä¿å­˜å‡½æ•° ===
    # actor.save_model("./runs/rl_models", epoch=0)
    # print("\n save_model æµ‹è¯•å®Œæˆï¼")

    # # #=== è°ƒç”¨åŠ è½½å‡½æ•° ===
    print("\n æ¨¡å‹ä¿å­˜å®Œæ¯•ï¼Œå¼€å§‹æµ‹è¯• load_model ...")
    # lora_dir = ""
    # actor.safe_load_model("/cpfs01/liuwei_workspace/models/finetune_rl/agent_checkpoint_epoch_6000", strict=True)
    print("\n load model æµ‹è¯•å®Œæˆï¼")

    # == åˆå¹¶ LoRA æµ‹è¯• ==
    # print("\n å¼€å§‹æµ‹è¯• merge_and_unload_lora ...")
    # actor.load_lora_and_merge_for_eval(
    #     checkpoint_dir="./runs/rl_models/agent_lora_epoch_30000",
    #     keep_dtype=TORCH_DTYPE,
    #     strict=True,)
    # print("\n merge_and_unload_lora æµ‹è¯•å®Œæˆï¼")

    # == åŠ è½½åˆå¹¶æ¨¡å‹æµ‹è¯• ==
    # print("\n å¼€å§‹æµ‹è¯• load_merged_model_for_eval ...")
    # actor.load_merged_model_for_eval(
    #     path="./runs/rl_models/agent_checkpoint_epoch_0",
    #     keep_dtype=TORCH_DTYPE,
    #     strict=True,
    #     device=actor.device,)
    # print("\n load_merged_model_for_eval æµ‹è¯•å®Œæˆï¼")
 
    parameter_groups = actor.get_parameter_groups()
    check_unnorm_key(cfg, actor.vla)
    actor.eval()

    # æ£€æŸ¥å‚æ•°ç±»å‹
    for key, value in actor.named_parameters():
        if value.dtype != TORCH_DTYPE:
            print(f"Warning: Parameter {key} has dtype {value.dtype}, expected {TORCH_DTYPE}.")
    print("ç­–ç•¥åˆå§‹åŒ–å®Œæˆã€‚")

    # ===== SwanLab & Excel setup =====
    # è¯†åˆ«é¢„è®­ç»ƒ checkpoint åç§°ä¸ LoRA å¼€å…³
    pretrained_str = str(cfg.pretrained_checkpoint)
    # ä½¿ç”¨æœ€åä¸€çº§ç›®å½•åä»¥é¿å…è¿‡é•¿çš„é¡¹ç›®å
    pretrained_name = os.path.basename(pretrained_str.rstrip("/")) or pretrained_str
    lora_flag = bool(getattr(cfg, "use_lora", False))
    lora_tag = "lora" if lora_flag else "nolora"

    # SwanLab åˆå§‹åŒ–ï¼ˆå¯é€‰ï¼‰
    if SWANLAB_AVAILABLE:
        try:
            # ä½¿ç”¨ç®€çŸ­çš„é¡¹ç›®åï¼šinference_{basename(pretrained_checkpoint)}_{lora}
            project_name = f"inference_{pretrained_name}_{lora_tag}"
            exp_name = f"libero_discrete_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
            SWANLAB_RUN = swanlab.init(
                project=project_name,
                experiment_name=exp_name,
                description=f"original_pretrained_checkpoint={pretrained_str}",
                config={
                    "pretrained_checkpoint": pretrained_str,
                    "use_lora": lora_flag,
                    "lora_rank": getattr(cfg, "lora_rank", None),
                    "benchmark": str(BENCHMARK),
                    "unnorm_key": str(cfg.unnorm_key),
                    "num_images_in_input": cfg.num_images_in_input,
                    "use_proprio": cfg.use_proprio,
                    "device": cfg.device,
                    "envs_num": envs_num,
                },
            )
        except Exception as e:
            print(f"SwanLab åˆå§‹åŒ–å¤±è´¥: {e}")

    # Excel/CSV ç»“æœè®°å½•
    records: List[Dict[str, Any]] = []
    out_dir = Path("./swanlog")
    out_dir.mkdir(parents=True, exist_ok=True)
    excel_path = out_dir / f"inference_{pretrained_name}_{lora_tag}.xlsx"
    csv_path = out_dir / f"inference_{pretrained_name}_{lora_tag}.csv"

    # åˆå§‹åŒ–ç¯å¢ƒ
    print(f"æ­£åœ¨åˆå§‹åŒ– {len(ENVS_ID)} ä¸ªå¹¶è¡Œçš„ Libero ç¯å¢ƒ...")
    envs = [
        LiberoEnvWrapper(
            benchmark_name=BENCHMARK,
            task_id=env_id,
            image_size=224,
            render_mode="rgb_array",
        )
        for env_id in ENVS_ID
    ]
    print("æ‰€æœ‰ç¯å¢ƒåˆå§‹åŒ–å®Œæˆã€‚")

    # å…¨å±€ç»Ÿè®¡
    total_episodes_finished = 0
    total_successes = 0

    from collections import deque

    # åˆå§‹åŒ–æ¯ä¸ªç¯å¢ƒçš„åŠ¨ä½œé˜Ÿåˆ—
    env_queues = [deque() for _ in range(len(ENVS_ID))]  # ENVS_IDæ˜¯ç¯å¢ƒIDåˆ—è¡¨

    # ä¸»å¾ªç¯
    while True:
        # åˆå§‹åŒ–ç¯å¢ƒçŠ¶æ€
        observations = []
        task_descriptions = []
        for i, env in enumerate(envs):
            obs, info = env.reset(seed=int(time.time()) + i)
            observations.append(obs)
            task_descriptions.append(env.task_description)
            print(f"ç¯å¢ƒ {i}: ä»»åŠ¡ ID = {env.task_id}, ä»»åŠ¡æè¿° = {env.task_description}")
            env_queues[i].clear()  # é‡ç½®è¯¥ç¯å¢ƒçš„åŠ¨ä½œé˜Ÿåˆ—

        # è·Ÿè¸ªå˜é‡
        active_envs = [True] * envs_num
        total_rewards = [0.0] * envs_num
        episode_steps = [0] * envs_num
        success_info = [False] * envs_num

        print(f"\nå¼€å§‹ç¬¬ {total_episodes_finished // envs_num + 1} è½®å¹¶è¡Œæ‰§è¡Œ...")

        # ç¯å¢ƒæ‰§è¡Œå¾ªç¯
        while any(active_envs):
            # 1. æ”¶é›†éœ€è¦ç”Ÿæˆæ–°åŠ¨ä½œçš„ç¯å¢ƒï¼ˆé˜Ÿåˆ—ä¸ºç©ºä¸”æ´»è·ƒçš„ç¯å¢ƒï¼‰
            need_generation_indices = []  # éœ€è¦ç”Ÿæˆæ–°åŠ¨ä½œçš„ç¯å¢ƒç´¢å¼•
            inputs_t_list = []  # éœ€è¦ç”Ÿæˆæ–°åŠ¨ä½œçš„ç¯å¢ƒè¾“å…¥
            
            for i in range(envs_num):
                if active_envs[i] and len(env_queues[i]) == 0:
                    inputs_t = prepare_one_obs(cfg, actor.processor, observations[i], task_descriptions[i], TORCH_DTYPE)
                    inputs_t_list.append(inputs_t)
                    need_generation_indices.append(i)
            
            # 2. ä¸ºéœ€è¦ç”Ÿæˆæ–°åŠ¨ä½œçš„ç¯å¢ƒæ‰¹é‡ç”ŸæˆåŠ¨ä½œ
            """
            inputs_t:<class 'transformers.image_processing_utils.BatchFeature'>
            input_ids torch.Size([1, 92])
            attention_mask torch.Size([1, 92])
            pixel_values torch.Size([1, 12, 224, 224])
            labels torch.Size([1, 92])
            proprio (8,)
            """ 
            if inputs_t_list:
                inputs_batch = actor.prepare_inputs_batch(inputs_t_list)
                """
                input_ids torch.Size([10, 93])
                attention_mask torch.Size([10, 93])
                pixel_values torch.Size([10, 12, 224, 224])
                labels torch.Size([10, 93])
                proprio torch.Size([10, 8])
                """
                with torch.inference_mode():
                    action_logits, _ = actor.forward(inputs_batch)
                B = action_logits.size(0)
                deterministic_flags = [True] * B  # è‹¥éœ€è´ªå¿ƒæ¨ç†ï¼Œæ”¹ä¸º [True] * B
                _, _, normalized_actions = actor.post_process(action_logits, deterministic_flags)  # å½¢çŠ¶ (B, 8, 7)
                                
                # å°†ç”Ÿæˆçš„åŠ¨ä½œåºåˆ—æ·»åŠ åˆ°å¯¹åº”ç¯å¢ƒçš„é˜Ÿåˆ—ä¸­
                for idx, env_idx in enumerate(need_generation_indices):
                    # è·å–è¯¥ç¯å¢ƒç”Ÿæˆçš„æ‰€æœ‰åŠ¨ä½œï¼ˆ8ä¸ªï¼‰
                    action_sequence = normalized_actions[idx]  # å½¢çŠ¶ (8, 7)
                    
                    # å°†æ•´ä¸ªåŠ¨ä½œåºåˆ—æ·»åŠ åˆ°é˜Ÿåˆ—
                    env_queues[env_idx].extend(action_sequence)  # ä½¿ç”¨extendæ‰¹é‡æ·»åŠ 
            
            # 3. æ‰§è¡ŒåŠ¨ä½œï¼ˆæ‰€æœ‰æ´»è·ƒç¯å¢ƒï¼‰
            for i in range(envs_num):
                if not active_envs[i]:
                    continue  # è·³è¿‡éæ´»è·ƒç¯å¢ƒ
                    
                # ç¡®ä¿é˜Ÿåˆ—ä¸­æœ‰åŠ¨ä½œï¼ˆå¦‚æœæ²¡æœ‰ï¼Œè¯´æ˜å‰é¢çš„ç”ŸæˆåŠ¨ä½œæ­¥éª¤æœ‰é—®é¢˜ï¼‰
                if len(env_queues[i]) == 0:
                    print(f"é”™è¯¯ï¼šç¯å¢ƒ {i} åŠ¨ä½œé˜Ÿåˆ—ä¸ºç©ºä½†æœªç”Ÿæˆæ–°åŠ¨ä½œ")
                    continue
                    
                # ä»é˜Ÿåˆ—ä¸­å–å‡ºåŠ¨ä½œ
                """
                å½’ä¸€åŒ–åˆ° [-1, 1] çš„ 7 ç»´å‘é‡
                """
                action_norm = env_queues[i].popleft()  # array([0.934, 0.469, -0.003, 0.000, 0.000, 0.000, 0.996])
                
                # å°†å½’ä¸€åŒ–åŠ¨ä½œè½¬æ¢ä¸ºç¯å¢ƒåŠ¨ä½œ
                """
                å°†å½’ä¸€åŒ–åŠ¨ä½œä» [-1, 1] æ˜ å°„å›ç¯å¢ƒæœŸæœ›çš„ç‰©ç†å°ºåº¦/å•ä½
                """
                action_env = actor.vla._unnormalize_actions(action_norm, cfg.unnorm_key)
                
                # æ‰§è¡ŒåŠ¨ä½œ
                obs, reward, terminated, truncated, info = envs[i].step(action_env)
                
                # æ›´æ–°çŠ¶æ€
                observations[i] = obs
                """
                - ç´¯ç§¯æ¯ä¸ªç¯å¢ƒå½“å‰ episode çš„æ€»å›æŠ¥ï¼ˆreturnï¼‰ï¼Œè€Œä¸æ˜¯åªè®°å½•æœ¬æ­¥å¥–åŠ±
                """
                total_rewards[i] += float(reward)
                episode_steps[i] += 1
                
                # å®šæœŸæ‰“å°
                if episode_steps[i] % 50 == 0:
                    print(f"ç¯å¢ƒ {i}, Step: {episode_steps[i]}, å¥–åŠ±: {reward:.4f}, ç»ˆæ­¢: {terminated}, æˆªæ–­: {truncated}")
                
                # æ£€æŸ¥ç¯å¢ƒæ˜¯å¦å®Œæˆ
                if terminated or truncated:
                    is_success = info.get('is_success', False)
                    total_successes += is_success
                    total_episodes_finished += 1
                    success_info[i] = is_success
                    
                    print("-" * 40)
                    print(f"ç¯å¢ƒ {i} å·²å®Œæˆ (ä»»åŠ¡: {envs[i].task_description[:50]}...)")
                    print(f"æ€»æ­¥æ•°: {episode_steps[i]}, æ€»å¥–åŠ±: {total_rewards[i]:.4f}, æ˜¯å¦æˆåŠŸ: {is_success}")
                    print(f"æˆåŠŸç‡: {total_successes/total_episodes_finished:.3f}, æ€»å›åˆæ•°: {total_episodes_finished}")
                    print("-" * 40)
                    
                    # é‡ç½®ç¯å¢ƒ
                    active_envs[i] = False
                    episode_steps[i] = 0
                    total_rewards[i] = 0
                    obs, info = envs[i].reset(seed=random.randint(0, 1000))
                    observations[i] = obs
                    env_queues[i].clear()  # é‡ç½®åŠ¨ä½œé˜Ÿåˆ—

        # æ¯è½®ç»“æŸåæ‰“å°ç»Ÿè®¡ä¿¡æ¯
        print("=" * 60)
        print(f"ç¬¬ {total_episodes_finished // envs_num} è½®å®Œæˆ!")
        print(f"ç´¯è®¡æ€»å›åˆæ•°: {total_episodes_finished}, æˆåŠŸæ¬¡æ•°: {total_successes}")
        print(f"æ€»ä½“æˆåŠŸç‡: {total_successes/total_episodes_finished:.3f}")
        print("=" * 60)

        # ===== æ¯5è½®è®°å½•åˆ° SwanLab ä¸ Excel/CSV =====
        round_idx = total_episodes_finished // envs_num
        # å½“å‰è½®çš„æˆåŠŸæ¬¡æ•°ï¼ˆåŸºäº success_infoï¼‰
        current_round_successes = sum(1 for s in success_info if s)
        current_round_success_rate = current_round_successes / float(envs_num)
        global_success_rate = total_successes / float(total_episodes_finished) if total_episodes_finished > 0 else 0.0

        if round_idx > 0 and round_idx % 5 == 0:
            # SwanLab è®°å½•
            if SWANLAB_AVAILABLE and SWANLAB_RUN is not None:
                try:
                    SWANLAB_RUN.log({
                        "round_idx": round_idx,
                        "round_success_rate": current_round_success_rate,
                        "round_successes": current_round_successes,
                        "global_success_rate": global_success_rate,
                        "total_successes": total_successes,
                        "total_episodes": total_episodes_finished,
                    }, step=round_idx)
                except Exception as e:
                    print(f"SwanLab è®°å½•å¤±è´¥: {e}")

            # ç»„è£…è®°å½•å¹¶å†™å…¥ Excel/CSV
            record = {
                "timestamp": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
                "round_idx": round_idx,
                "round_success_rate": current_round_success_rate,
                "round_successes": current_round_successes,
                "global_success_rate": global_success_rate,
                "total_successes": total_successes,
                "total_episodes": total_episodes_finished,
                "pretrained_checkpoint": pretrained_str,
                "use_lora": lora_flag,
                "lora_rank": getattr(cfg, "lora_rank", None),
                "benchmark": str(BENCHMARK),
                "unnorm_key": str(cfg.unnorm_key),
                "envs_num": envs_num,
            }
            records.append(record)

            # ä¿å­˜è®°å½•ï¼ˆä¼˜å…ˆ Excelï¼Œå¤±è´¥æˆ–æ—  pandas åˆ™ä¿å­˜ä¸º CSVï¼‰
            saved_path = None
            if PANDAS_AVAILABLE:
                try:
                    df = pd.DataFrame(records)
                    df.to_excel(excel_path, index=False)
                    saved_path = excel_path
                except Exception as e:
                    print(f"å†™å…¥ Excel å¤±è´¥ï¼Œé™çº§ä¸º CSV: {e}")
            if saved_path is None:
                try:
                    write_header = not csv_path.exists()
                    with open(csv_path, "a", newline="", encoding="utf-8") as f:
                        writer = csv.DictWriter(f, fieldnames=list(record.keys()))
                        if write_header:
                            writer.writeheader()
                        writer.writerow(record)
                    saved_path = csv_path
                except Exception as e:
                    print(f"ä¿å­˜è®°å½•å¤±è´¥: {e}")
            if saved_path is not None:
                print(f"âœ… è®°å½•å·²ä¿å­˜: {saved_path}")